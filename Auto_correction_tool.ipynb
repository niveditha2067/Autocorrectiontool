{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWtUvF4EXaoq",
        "outputId": "f7650c54-df3e-45b8-ac1b-c21ee89b9b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pattern) (0.18.3)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m945.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pattern) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pattern) (4.9.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pattern) (3.8.1)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.4/348.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pattern) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pattern) (2.4.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (9.1.0)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-4.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (1.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (40.0.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (3.4)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.6.0-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.2.2-py3-none-any.whl (13 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.11.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->pattern) (67.7.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.7.1)\n",
            "Collecting autocommand\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (6.0.4)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (1.10.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (4.5.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332718 sha256=fc61910ecdfa37928e9feef4dcaede1efadd780f6a796f7240c694553c909b3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8f/40/fe23abd593ef60be5bfaf3e02154d3484df42aa947bbf4d499\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp310-cp310-linux_x86_64.whl size=108349 sha256=021e47bfbac9b493a743e4ce839657086f7d0fc9557573fa3efec5fb420f4d75\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/34/ba/a769c165b01646816afdf9bf792e847ef149693fee432b6b65\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=dc9d27f03f7bb8975eeb17a61fd1bab16ec14547cda02bfec885dede21c04e72\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=f53ca50c71134ab2aebc584d64ba8d8315fd3c68aac7a8814c70e72a5183016d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: sgmllib3k, backports.csv, zc.lockfile, python-docx, mysqlclient, jaraco.functools, jaraco.context, feedparser, autocommand, tempora, cheroot, portend, pdfminer.six, jaraco.text, jaraco.collections, cherrypy, pattern\n",
            "Successfully installed autocommand-2.2.2 backports.csv-1.0.7 cheroot-9.0.0 cherrypy-18.8.0 feedparser-6.0.10 jaraco.collections-4.1.0 jaraco.context-4.3.0 jaraco.functools-3.6.0 jaraco.text-3.11.1 mysqlclient-2.1.1 pattern-3.6 pdfminer.six-20221105 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.2.2 zc.lockfile-3.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622380 sha256=9820fc8e152c087a8fffc5e5d568592002f4a512506b34f0aeadc90b6672376c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/7b/6d/b76b29ce11ff8e2521c8c7dd0e5bfee4fb1789d76193124343\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textdistance\n",
            "  Downloading textdistance-4.5.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pattern\n",
        "!pip install pyspellchecker\n",
        "!pip install autocorrect\n",
        "!pip install textblob\n",
        "!pip install textdistance\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # regular expression\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Implement the function process_data which\n",
        "# 1) Reads in a corpus\n",
        "# 2) Changes everything to lowercase\n",
        "# 3) Returns a list of words.\n",
        "\n",
        "w = [] #words\n",
        "with open('sample.txt','r',encoding=\"utf8\") as f:\n",
        "    file_name_data = f.read()\n",
        "    file_name_data = file_name_data.lower()\n",
        "    w = re.findall('\\w+', file_name_data)\n",
        "\n",
        "v = set(w) #vocabulary\n",
        "print(f\"The first 10 words in our dictionary are: \\n{w[0:10]}\")\n",
        "print(f\"The dictionary has {len(v)} words \")\n"
      ],
      "metadata": {
        "id": "vE7oBMGcPsbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(words):\n",
        "    word_count_dict = {}\n",
        "    for word in words:\n",
        "        if word in word_count_dict:\n",
        "            word_count_dict[word] += 1\n",
        "        else:\n",
        "            word_count_dict[word] = 1\n",
        "    return word_count_dict\n",
        "word_count_dict = get_count(w)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n"
      ],
      "metadata": {
        "id": "hryw2JhXdhYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DeleteLetter(word):\n",
        "    delete_list = []\n",
        "    split_list = []\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "    for a, b in split_list:\n",
        "        delete_list.append(a + b[1:])\n",
        "    return delete_list\n",
        "\n",
        "delete_word_l = DeleteLetter(word=\"cans\")\n"
      ],
      "metadata": {
        "id": "FuTrwgIedsMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DeleteLetter(\"Dicet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hziqi_Cdx9E",
        "outputId": "cb697688-652e-451d-e449-dac33f6662bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['icet', 'Dcet', 'Diet', 'Dict', 'Dice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SwitchLetter(word):\n",
        "    split_l = []\n",
        "    switch_l = []\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_l if len(b) >= 2]\n",
        "    return switch_l\n",
        "\n",
        "switch_word_l = SwitchLetter(word=\"habeat\")\n",
        "print(SwitchLetter(\"habeat\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjEY18vkd0Mv",
        "outputId": "655d5305-102a-4de6-91dc-c8e5982efcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ahbeat', 'hbaeat', 'haebat', 'habaet', 'habeta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(word):\n",
        "    split_l = []\n",
        "    replace_list = []\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_list = [a + l + (b[1:] if len(b) > 1 else '') for a, b in split_l if b for l in alphabets]\n",
        "    return replace_list\n",
        "\n",
        "replace_l = replace_letter(word='appetitum')\n",
        "print(replace_letter(\"appetitum\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeHViMXId4nA",
        "outputId": "156572e5-cc4d-49e8-8d83-02f5c6fa4509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['appetitum', 'bppetitum', 'cppetitum', 'dppetitum', 'eppetitum', 'fppetitum', 'gppetitum', 'hppetitum', 'ippetitum', 'jppetitum', 'kppetitum', 'lppetitum', 'mppetitum', 'nppetitum', 'oppetitum', 'pppetitum', 'qppetitum', 'rppetitum', 'sppetitum', 'tppetitum', 'uppetitum', 'vppetitum', 'wppetitum', 'xppetitum', 'yppetitum', 'zppetitum', 'aapetitum', 'abpetitum', 'acpetitum', 'adpetitum', 'aepetitum', 'afpetitum', 'agpetitum', 'ahpetitum', 'aipetitum', 'ajpetitum', 'akpetitum', 'alpetitum', 'ampetitum', 'anpetitum', 'aopetitum', 'appetitum', 'aqpetitum', 'arpetitum', 'aspetitum', 'atpetitum', 'aupetitum', 'avpetitum', 'awpetitum', 'axpetitum', 'aypetitum', 'azpetitum', 'apaetitum', 'apbetitum', 'apcetitum', 'apdetitum', 'apeetitum', 'apfetitum', 'apgetitum', 'aphetitum', 'apietitum', 'apjetitum', 'apketitum', 'apletitum', 'apmetitum', 'apnetitum', 'apoetitum', 'appetitum', 'apqetitum', 'apretitum', 'apsetitum', 'aptetitum', 'apuetitum', 'apvetitum', 'apwetitum', 'apxetitum', 'apyetitum', 'apzetitum', 'appatitum', 'appbtitum', 'appctitum', 'appdtitum', 'appetitum', 'appftitum', 'appgtitum', 'apphtitum', 'appititum', 'appjtitum', 'appktitum', 'appltitum', 'appmtitum', 'appntitum', 'appotitum', 'appptitum', 'appqtitum', 'apprtitum', 'appstitum', 'appttitum', 'apputitum', 'appvtitum', 'appwtitum', 'appxtitum', 'appytitum', 'appztitum', 'appeaitum', 'appebitum', 'appecitum', 'appeditum', 'appeeitum', 'appefitum', 'appegitum', 'appehitum', 'appeiitum', 'appejitum', 'appekitum', 'appelitum', 'appemitum', 'appenitum', 'appeoitum', 'appepitum', 'appeqitum', 'apperitum', 'appesitum', 'appetitum', 'appeuitum', 'appevitum', 'appewitum', 'appexitum', 'appeyitum', 'appezitum', 'appetatum', 'appetbtum', 'appetctum', 'appetdtum', 'appetetum', 'appetftum', 'appetgtum', 'appethtum', 'appetitum', 'appetjtum', 'appetktum', 'appetltum', 'appetmtum', 'appetntum', 'appetotum', 'appetptum', 'appetqtum', 'appetrtum', 'appetstum', 'appetttum', 'appetutum', 'appetvtum', 'appetwtum', 'appetxtum', 'appetytum', 'appetztum', 'appetiaum', 'appetibum', 'appeticum', 'appetidum', 'appetieum', 'appetifum', 'appetigum', 'appetihum', 'appetiium', 'appetijum', 'appetikum', 'appetilum', 'appetimum', 'appetinum', 'appetioum', 'appetipum', 'appetiqum', 'appetirum', 'appetisum', 'appetitum', 'appetiuum', 'appetivum', 'appetiwum', 'appetixum', 'appetiyum', 'appetizum', 'appetitam', 'appetitbm', 'appetitcm', 'appetitdm', 'appetitem', 'appetitfm', 'appetitgm', 'appetithm', 'appetitim', 'appetitjm', 'appetitkm', 'appetitlm', 'appetitmm', 'appetitnm', 'appetitom', 'appetitpm', 'appetitqm', 'appetitrm', 'appetitsm', 'appetittm', 'appetitum', 'appetitvm', 'appetitwm', 'appetitxm', 'appetitym', 'appetitzm', 'appetitua', 'appetitub', 'appetituc', 'appetitud', 'appetitue', 'appetituf', 'appetitug', 'appetituh', 'appetitui', 'appetituj', 'appetituk', 'appetitul', 'appetitum', 'appetitun', 'appetituo', 'appetitup', 'appetituq', 'appetitur', 'appetitus', 'appetitut', 'appetituu', 'appetituv', 'appetituw', 'appetitux', 'appetituy', 'appetituz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word):\n",
        "    split_l = []\n",
        "    insert_list = []\n",
        "    for i in range(len(word) + 1):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_list = [a + l + b for a, b in split_l for l in letters]\n",
        "    # print(split_l)\n",
        "    return insert_list\n",
        "print(insert_letter(\"orationem\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-qJ2GuYeTaD",
        "outputId": "f9666dac-b9a9-44ec-fcab-8e9b13833396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aorationem', 'borationem', 'corationem', 'dorationem', 'eorationem', 'forationem', 'gorationem', 'horationem', 'iorationem', 'jorationem', 'korationem', 'lorationem', 'morationem', 'norationem', 'oorationem', 'porationem', 'qorationem', 'rorationem', 'sorationem', 'torationem', 'uorationem', 'vorationem', 'worationem', 'xorationem', 'yorationem', 'zorationem', 'oarationem', 'obrationem', 'ocrationem', 'odrationem', 'oerationem', 'ofrationem', 'ogrationem', 'ohrationem', 'oirationem', 'ojrationem', 'okrationem', 'olrationem', 'omrationem', 'onrationem', 'oorationem', 'oprationem', 'oqrationem', 'orrationem', 'osrationem', 'otrationem', 'ourationem', 'ovrationem', 'owrationem', 'oxrationem', 'oyrationem', 'ozrationem', 'oraationem', 'orbationem', 'orcationem', 'ordationem', 'oreationem', 'orfationem', 'orgationem', 'orhationem', 'oriationem', 'orjationem', 'orkationem', 'orlationem', 'ormationem', 'ornationem', 'oroationem', 'orpationem', 'orqationem', 'orrationem', 'orsationem', 'ortationem', 'oruationem', 'orvationem', 'orwationem', 'orxationem', 'oryationem', 'orzationem', 'oraationem', 'orabtionem', 'oractionem', 'oradtionem', 'oraetionem', 'oraftionem', 'oragtionem', 'orahtionem', 'oraitionem', 'orajtionem', 'oraktionem', 'oraltionem', 'oramtionem', 'orantionem', 'oraotionem', 'oraptionem', 'oraqtionem', 'orartionem', 'orastionem', 'orattionem', 'orautionem', 'oravtionem', 'orawtionem', 'oraxtionem', 'oraytionem', 'oraztionem', 'orataionem', 'oratbionem', 'oratcionem', 'oratdionem', 'orateionem', 'oratfionem', 'oratgionem', 'orathionem', 'oratiionem', 'oratjionem', 'oratkionem', 'oratlionem', 'oratmionem', 'oratnionem', 'oratoionem', 'oratpionem', 'oratqionem', 'oratrionem', 'oratsionem', 'orattionem', 'oratuionem', 'oratvionem', 'oratwionem', 'oratxionem', 'oratyionem', 'oratzionem', 'oratiaonem', 'oratibonem', 'oraticonem', 'oratidonem', 'oratieonem', 'oratifonem', 'oratigonem', 'oratihonem', 'oratiionem', 'oratijonem', 'oratikonem', 'oratilonem', 'oratimonem', 'oratinonem', 'oratioonem', 'oratiponem', 'oratiqonem', 'oratironem', 'oratisonem', 'oratitonem', 'oratiuonem', 'orativonem', 'oratiwonem', 'oratixonem', 'oratiyonem', 'oratizonem', 'oratioanem', 'oratiobnem', 'oratiocnem', 'oratiodnem', 'oratioenem', 'oratiofnem', 'oratiognem', 'oratiohnem', 'oratioinem', 'oratiojnem', 'oratioknem', 'oratiolnem', 'oratiomnem', 'orationnem', 'oratioonem', 'oratiopnem', 'oratioqnem', 'oratiornem', 'oratiosnem', 'oratiotnem', 'oratiounem', 'oratiovnem', 'oratiownem', 'oratioxnem', 'oratioynem', 'oratioznem', 'orationaem', 'orationbem', 'orationcem', 'orationdem', 'orationeem', 'orationfem', 'orationgem', 'orationhem', 'orationiem', 'orationjem', 'orationkem', 'orationlem', 'orationmem', 'orationnem', 'orationoem', 'orationpem', 'orationqem', 'orationrem', 'orationsem', 'orationtem', 'orationuem', 'orationvem', 'orationwem', 'orationxem', 'orationyem', 'orationzem', 'orationeam', 'orationebm', 'orationecm', 'orationedm', 'orationeem', 'orationefm', 'orationegm', 'orationehm', 'orationeim', 'orationejm', 'orationekm', 'orationelm', 'orationemm', 'orationenm', 'orationeom', 'orationepm', 'orationeqm', 'orationerm', 'orationesm', 'orationetm', 'orationeum', 'orationevm', 'orationewm', 'orationexm', 'orationeym', 'orationezm', 'orationema', 'orationemb', 'orationemc', 'orationemd', 'orationeme', 'orationemf', 'orationemg', 'orationemh', 'orationemi', 'orationemj', 'orationemk', 'orationeml', 'orationemm', 'orationemn', 'orationemo', 'orationemp', 'orationemq', 'orationemr', 'orationems', 'orationemt', 'orationemu', 'orationemv', 'orationemw', 'orationemx', 'orationemy', 'orationemz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches=True):\n",
        "    edit_set1 = set()\n",
        "    edit_set1.update(DeleteLetter(word))\n",
        "    if allow_switches:\n",
        "        edit_set1.update(SwitchLetter(word))\n",
        "    edit_set1.update(replace_letter(word))\n",
        "    edit_set1.update(insert_letter(word))\n",
        "    return edit_set1\n",
        "\n",
        "# edit two letters\n",
        "def edit_two_letters(word, allow_switches=True):\n",
        "    edit_set2 = set()\n",
        "    edit_one = edit_one_letter(word, allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = edit_one_letter(w, allow_switches=allow_switches)\n",
        "            edit_set2.update(edit_two)\n",
        "    return edit_set2\n",
        "\n",
        "# get corrected word\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    suggested_word = []\n",
        "    best_suggestion = []\n",
        "    suggested_word = list(\n",
        "        (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
        "            vocab))\n",
        "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "    return best_suggestion\n",
        "\n",
        "my_word = input(\"Enter any word:\")\n",
        "probs = get_probs(word_count_dict)\n",
        "tmp_corrections = get_corrections(my_word, probs, v, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
      ],
      "metadata": {
        "id": "vOourblrecdm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}